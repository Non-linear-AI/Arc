"""ML Trainer specification generation and training execution tool."""

from __future__ import annotations

import asyncio
from pathlib import Path
from typing import TYPE_CHECKING, Any

import yaml

if TYPE_CHECKING:
    from arc.ml.runtime import MLRuntime

from arc.core.agents.ml_train import MLTrainAgent
from arc.graph.trainer import TrainerValidationError, validate_trainer_dict
from arc.ml.runtime import MLRuntimeError
from arc.tools.base import BaseTool, ToolResult
from arc.utils.yaml_workflow import YamlConfirmationWorkflow


class MLTrainTool(BaseTool):
    """Unified tool for generating trainer specs and launching training.

    This tool combines trainer generation with training execution in a single
    workflow, similar to the model generator pattern. It provides:
    1. Trainer spec generation via LLM
    2. Interactive confirmation workflow for trainer spec
    3. Auto-registration to database
    4. Interactive confirmation workflow for training launch
    5. Training execution

    All training configuration (epochs, batch_size, learning_rate, etc.) must
    be defined in the trainer YAML - no runtime overrides are supported.
    """

    def __init__(
        self,
        services,
        runtime: MLRuntime,
        api_key: str | None,
        base_url: str | None,
        model: str | None,
        ui_interface,
        tensorboard_manager=None,
    ) -> None:
        self.services = services
        self.runtime = runtime
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.ui = ui_interface
        self.tensorboard_manager = tensorboard_manager

    async def execute(
        self,
        *,
        name: str | None = None,
        instruction: str | None = None,
        model_id: str | None = None,
        train_table: str | None = None,
        auto_confirm: bool = False,
        ml_plan: dict | None = None,
    ) -> ToolResult:
        """Generate trainer spec, register it, and launch training with confirmation.

        Args:
            name: Trainer name
            instruction: User's instruction for training configuration (PRIMARY driver)
            model_id: Model ID (with version, e.g., 'my_model-v1')
            train_table: Training data table
            auto_confirm: Skip confirmation workflows (for testing only)
            ml_plan: Optional ML plan dict containing training_configuration guidance
                (SECONDARY baseline, automatically injected by the main agent)

        Note on instruction vs ml_plan precedence:
            - instruction: PRIMARY driver - user's immediate, specific request
            - ml_plan: SECONDARY baseline - background guidance and context
            - When there's a conflict, instruction takes precedence
            - Example: If instruction says "use 10 epochs" but plan says "use 5 epochs",
              the trainer spec should use 10 epochs (instruction wins)
            - The LLM agent should use ml_plan as baseline context and augment/override
              it with specifics from instruction

        Note on training configuration:
            All training configuration (epochs, batch_size, learning_rate, validation,
            etc.) must be specified in the trainer YAML generated by the LLM.
            No runtime overrides are supported.
        """
        # Show section title first, before any validation
        # Keep the section printer reference to use for all messages including errors
        ml_trainer_section_printer = None
        if self.ui:
            self._ml_trainer_section = self.ui._printer.section(
                color="magenta", add_dot=True
            )
            ml_trainer_section_printer = self._ml_trainer_section.__enter__()
            ml_trainer_section_printer.print("ML Train")

        # Helper to close section and return error
        def _error_in_section(message: str) -> ToolResult:
            if ml_trainer_section_printer:
                ml_trainer_section_printer.print("")
                ml_trainer_section_printer.print(f" {message}")
            if self.ui and hasattr(self, "_ml_trainer_section"):
                self._ml_trainer_section.__exit__(None, None, None)
            return ToolResult(success=False, output="", metadata={"error_shown": True})

        # Validate API key and services
        if not self.api_key:
            return _error_in_section(
                "API key required for trainer generation. "
                "Set ARC_API_KEY or configure an API key before using this tool."
            )

        if not self.services:
            return _error_in_section(
                "Trainer generation service unavailable. "
                "Database services not initialized."
            )

        # Validate required parameters
        if not name or not instruction or not model_id or not train_table:
            return _error_in_section(
                "Parameters 'name', 'instruction', 'model_id', and 'train_table' "
                "are required."
            )

        # Get the registered model by ID
        try:
            model_record = self.services.models.get_model_by_id(str(model_id))
            if not model_record:
                return _error_in_section(
                    f"Model '{model_id}' not found in registry. "
                    "Please check the model ID or register the model first."
                )
        except Exception as exc:
            return _error_in_section(f"Failed to retrieve model '{model_id}': {exc}")

        # Show generation status
        if ml_trainer_section_printer:
            ml_trainer_section_printer.print(
                "[dim]Generating Arc-Graph trainer specification...[/dim]"
            )

        # Extract training configuration from ML plan if provided (Phase 6)
        ml_plan_training_config = None
        if ml_plan:
            from arc.core.ml_plan import MLPlan

            plan = MLPlan.from_dict(ml_plan)
            ml_plan_training_config = plan.training_configuration

        # Extract knowledge IDs from instruction and ML Plan
        from arc.core.agents.shared.knowledge_selector import (
            extract_knowledge_ids_from_text,
        )

        recommended_knowledge_ids = extract_knowledge_ids_from_text(
            instruction=instruction,
            ml_plan_architecture=ml_plan_training_config,
        )

        # Generate trainer spec via LLM
        agent = MLTrainAgent(
            self.services,
            self.api_key,
            self.base_url,
            self.model,
        )

        try:
            (
                trainer_spec,
                trainer_yaml,
                conversation_history,
            ) = await agent.generate_trainer(
                name=str(name),
                instruction=str(instruction),
                model_id=model_record.id,
                model_spec_yaml=model_record.spec,
                ml_plan_training_config=ml_plan_training_config,
                recommended_knowledge_ids=recommended_knowledge_ids,
            )
        except Exception as exc:
            from arc.core.agents.ml_train import MLTrainError

            # Print error within the ML Trainer section
            if ml_trainer_section_printer:
                ml_trainer_section_printer.print("")
                ml_trainer_section_printer.print(f" {str(exc)}")
            # Close the section before returning
            if self.ui and hasattr(self, "_ml_trainer_section"):
                self._ml_trainer_section.__exit__(None, None, None)

            if isinstance(exc, MLTrainError):
                return ToolResult(
                    success=False, output="", metadata={"error_shown": True}
                )
            return ToolResult(success=False, output="", metadata={"error_shown": True})

        # Validate the generated trainer
        try:
            trainer_dict = yaml.safe_load(trainer_yaml)
            validate_trainer_dict(trainer_dict)
        except (yaml.YAMLError, TrainerValidationError) as exc:
            # Print error within the ML Trainer section
            if ml_trainer_section_printer:
                ml_trainer_section_printer.print("")
                ml_trainer_section_printer.print(f" Trainer validation failed: {exc}")
            # Close the section before returning
            if self.ui and hasattr(self, "_ml_trainer_section"):
                self._ml_trainer_section.__exit__(None, None, None)
            return ToolResult(success=False, output="", metadata={"error_shown": True})
        except Exception as exc:
            import logging

            logging.exception("Unexpected error during trainer validation")
            # Print error within the ML Trainer section
            if ml_trainer_section_printer:
                ml_trainer_section_printer.print("")
                ml_trainer_section_printer.print(
                    f" Unexpected validation error: {exc.__class__.__name__}: {exc}"
                )
            # Close the section before returning
            if self.ui and hasattr(self, "_ml_trainer_section"):
                self._ml_trainer_section.__exit__(None, None, None)
            return ToolResult(success=False, output="", metadata={"error_shown": True})

        # Interactive confirmation workflow (unless auto_confirm is True)
        if not auto_confirm:
            workflow = YamlConfirmationWorkflow(
                validator_func=self._create_validator(),
                editor_func=self._create_editor(instruction, model_record),
                ui_interface=self.ui,
                yaml_type_name="trainer",
                yaml_suffix=".arc-trainer.yaml",
            )

            context_dict = {
                "trainer_name": str(name),
                "instruction": str(instruction),
                "model_id": model_record.id,
                "model_spec_yaml": model_record.spec,
            }

            try:
                proceed, final_yaml = await workflow.run_workflow(
                    trainer_yaml,
                    context_dict,
                    None,  # No output path - we register to DB
                    conversation_history,  # Pass conversation history for editing
                )
                if not proceed:
                    # Close the section before returning
                    if self.ui and hasattr(self, "_ml_trainer_section"):
                        self._ml_trainer_section.__exit__(None, None, None)
                    return ToolResult(
                        success=True,
                        output=" Trainer generation cancelled.",
                        metadata={"cancelled": True},
                    )
                trainer_yaml = final_yaml
            finally:
                workflow.cleanup()

        # Auto-register trainer to database
        try:
            # Extract plan_id from ml_plan if provided
            plan_id = ml_plan.get("plan_id") if ml_plan else None

            trainer_record = self.runtime.create_trainer(
                name=str(name),
                model_id=str(model_id),
                schema_yaml=trainer_yaml,
                description=f"Generated trainer for model {model_id}",
                plan_id=plan_id,
            )

            # Display registration confirmation in the ML Trainer section
            if ml_trainer_section_printer:
                ml_trainer_section_printer.print("")  # Empty line before confirmation
                ml_trainer_section_printer.print(
                    f"[dim]âœ“ Trainer '{name}' registered to database "
                    f"({trainer_record.id} â€¢ Model: {trainer_spec.model_ref} â€¢ "
                    f"Optimizer: {trainer_spec.optimizer.type})[/dim]"
                )
        except Exception as exc:
            return ToolResult.error_result(f"Failed to register trainer: {exc}")

        # Build simple output for ToolResult (detailed output already shown in UI)
        lines = [f"Trainer '{name}' registered successfully as {trainer_record.id}"]

        # Build result metadata (before auto-launch to use in error handling)
        result_metadata = {
            "trainer_id": trainer_record.id,
            "trainer_name": name,
            "model_id": model_record.id,
            "yaml_content": trainer_yaml,
            "training_launched": False,  # Will update if training launches
        }

        # Auto-launch training after trainer is accepted
        job_id = None

        if True:  # Always train when trainer is accepted
            if ml_trainer_section_printer:
                ml_trainer_section_printer.print("")  # Empty line before training
                ml_trainer_section_printer.print(
                    f" Launching training with trainer '{name}'..."
                )

            try:
                job_id = await asyncio.to_thread(
                    self.runtime.train_with_trainer,
                    trainer_name=str(name),
                    train_table=str(train_table),
                )

                lines.append("")
                lines.append(" Training job submitted successfully.")
                lines.append(f"Training table: {train_table}")
                lines.append(f"Job ID: {job_id}")

                # Show training success message in section
                if ml_trainer_section_printer:
                    ml_trainer_section_printer.print("")
                    ml_trainer_section_printer.print(
                        "[dim] Training job submitted successfully.[/dim]"
                    )
                    ml_trainer_section_printer.print(
                        f"[dim]Training table: {train_table}[/dim]"
                    )
                    ml_trainer_section_printer.print(f"[dim]Job ID: {job_id}[/dim]")

                # Show job monitoring instructions in section
                if ml_trainer_section_printer:
                    ml_trainer_section_printer.print("")
                    ml_trainer_section_printer.print(
                        "[dim][cyan]9 Monitor training progress:[/cyan][/dim]"
                    )
                    ml_trainer_section_printer.print(
                        f"[dim]  â€¢ Status: /ml jobs status {job_id}[/dim]"
                    )
                    ml_trainer_section_printer.print(
                        f"[dim]  â€¢ Logs: /ml jobs logs {job_id}[/dim]"
                    )

                # Handle TensorBoard launch
                if not auto_confirm and self.ui:
                    if self.tensorboard_manager:
                        try:
                            await self._handle_tensorboard_launch(
                                job_id, ml_trainer_section_printer
                            )
                        except (OSError, RuntimeError) as e:
                            # Known TensorBoard launch failures
                            if ml_trainer_section_printer:
                                ml_trainer_section_printer.print(
                                    f"[yellow]  TensorBoard setup failed: {e}[/yellow]"
                                )
                            self._show_manual_tensorboard_instructions(
                                job_id, ml_trainer_section_printer
                            )
                        except Exception as e:
                            # Log unexpected errors with full traceback
                            import logging

                            logging.exception(
                                "Unexpected error during TensorBoard launch"
                            )
                            error_msg = f"{e.__class__.__name__}: {e}"
                            if ml_trainer_section_printer:
                                ml_trainer_section_printer.print(
                                    "[yellow]  TensorBoard setup failed:[/yellow]"
                                )
                                ml_trainer_section_printer.print(
                                    f"[yellow]{error_msg}[/yellow]"
                                )
                            self._show_manual_tensorboard_instructions(
                                job_id, ml_trainer_section_printer
                            )
                    else:
                        # No TensorBoard manager available
                        if ml_trainer_section_printer:
                            ml_trainer_section_printer.print(
                                "[dim]9  TensorBoard auto-launch not available "
                                "(restart arc chat to enable)[/dim]"
                            )
                        self._show_manual_tensorboard_instructions(
                            job_id, ml_trainer_section_printer
                        )

                # Training job launched successfully - job status can be
                # checked separately. The agent will monitor job status and
                # analyze results when training completes

            except MLRuntimeError as exc:
                # Trainer was successfully registered but training launch failed
                # Display error in section and return success with warning since
                # trainer is usable
                if ml_trainer_section_printer:
                    ml_trainer_section_printer.print(" Training Validation Failed")
                    ml_trainer_section_printer.print("")
                    ml_trainer_section_printer.print(f"[red]{exc}[/red]")
                    ml_trainer_section_printer.print("")
                    ml_trainer_section_printer.print(
                        f"[dim]Note: Trainer '{name}' was registered successfully[/dim]"
                    )
                    retry_cmd = f"/ml jobs submit --trainer {name} --data {train_table}"
                    ml_trainer_section_printer.print(f"[dim]Retry: {retry_cmd}[/dim]")

                lines.append("")
                lines.append(" Training Validation Failed")
                lines.append("")
                lines.append(f"{exc}")
                lines.append("")
                lines.append(f"Note: Trainer '{name}' was registered successfully")
                retry_cmd = f"/ml jobs submit --trainer {name} --data {train_table}"
                lines.append(f"Retry: {retry_cmd}")

                # Extract validation report if available for agent debugging
                validation_report = getattr(exc, "validation_report", None)

                metadata = {
                    **result_metadata,
                    "training_launch_failed": True,
                    "training_error": str(exc),
                }

                # Include detailed validation report for agent debugging
                if validation_report:
                    metadata["validation_report"] = validation_report

                return ToolResult(
                    success=True,  # Trainer registration succeeded
                    output="\n".join(lines),
                    metadata=metadata,
                )
            except Exception as exc:
                # Log unexpected errors with full traceback
                import logging

                logging.exception("Unexpected error during training launch")

                # Trainer was successfully registered but training launch failed
                # Display error in section
                if ml_trainer_section_printer:
                    ml_trainer_section_printer.print(" Training Validation Failed")
                    ml_trainer_section_printer.print("")
                    ml_trainer_section_printer.print(
                        f"[red]{exc.__class__.__name__}: {exc}[/red]"
                    )
                    ml_trainer_section_printer.print("")
                    ml_trainer_section_printer.print(
                        f"[dim]Note: Trainer '{name}' was registered successfully[/dim]"
                    )
                    retry_cmd = f"/ml jobs submit --trainer {name} --data {train_table}"
                    ml_trainer_section_printer.print(f"[dim]Retry: {retry_cmd}[/dim]")

                lines.append("")
                lines.append(" Training Validation Failed")
                lines.append("")
                lines.append(f"{exc.__class__.__name__}: {exc}")
                lines.append("")
                lines.append(f"Note: Trainer '{name}' was registered successfully")
                retry_cmd = f"/ml jobs submit --trainer {name} --data {train_table}"
                lines.append(f"Retry: {retry_cmd}")

                # Extract validation report if available (might not be present)
                validation_report = getattr(exc, "validation_report", None)

                metadata = {
                    **result_metadata,
                    "training_launch_failed": True,
                    "training_error": f"{exc.__class__.__name__}: {exc}",
                }

                if validation_report:
                    metadata["validation_report"] = validation_report

                return ToolResult(
                    success=True,  # Trainer registration succeeded
                    output="\n".join(lines),
                    metadata=metadata,
                )

        # Build result metadata
        result_metadata = {
            "trainer_id": trainer_record.id,
            "trainer_name": name,
            "model_id": model_record.id,
            "yaml_content": trainer_yaml,
            "training_launched": job_id is not None,
            "from_ml_plan": ml_plan is not None,
        }

        if job_id:
            result_metadata["job_id"] = job_id

        # Close the ML Trainer section
        if self.ui and hasattr(self, "_ml_trainer_section"):
            self._ml_trainer_section.__exit__(None, None, None)

        return ToolResult(
            success=True,
            output="\n".join(lines),
            metadata=result_metadata,
        )

    async def _handle_tensorboard_launch(self, job_id: str, section_printer=None):
        """Handle TensorBoard launch based on user preference.

        Args:
            job_id: Training job identifier
            section_printer: Section printer for indented output
        """

        from arc.core.config import SettingsManager
        from arc.utils.tensorboard_workflow import prompt_tensorboard_preference

        settings = SettingsManager()
        mode = settings.get_tensorboard_mode()

        # First time - no preference set, show combined dialog
        if mode is None:
            mode, should_launch = await prompt_tensorboard_preference(self.ui)
            settings.set_tensorboard_mode(mode)
            if section_printer:
                section_printer.print("")
                section_printer.print(
                    f"[green] TensorBoard preference saved: {mode}[/green]"
                )
            else:
                self.ui._printer.console.print()
                self.ui._printer.console.print(
                    f"[green] TensorBoard preference saved: {mode}[/green]"
                )

            # Launch immediately if user chose to
            if should_launch:
                await self._launch_tensorboard(job_id, section_printer)
            else:
                self._show_manual_tensorboard_instructions(job_id, section_printer)

        # Subsequent times - respect saved preference
        elif mode == "always":
            await self._launch_tensorboard(job_id, section_printer)
        elif mode == "ask":
            if section_printer:
                section_printer.print("")
                section_printer.print(
                    "[cyan]Launch TensorBoard? (http://localhost:6006)[/cyan]"
                )
            else:
                self.ui._printer.console.print()
                self.ui._printer.console.print(
                    "[cyan]Launch TensorBoard? (http://localhost:6006)[/cyan]"
                )
            choice = await self.ui._printer.get_choice_async(
                options=[
                    ("yes", "Yes, launch now"),
                    ("always", "Always launch automatically"),
                    ("no", "No, skip"),
                ],
                default="yes",
            )

            # Handle the choice
            if choice == "always":
                # Update preference to always
                settings.set_tensorboard_mode("always")
                if section_printer:
                    section_printer.print("")
                    section_printer.print(
                        "[green] TensorBoard preference updated: always[/green]"
                    )
                else:
                    self.ui._printer.console.print()
                    self.ui._printer.console.print(
                        "[green] TensorBoard preference updated: always[/green]"
                    )
                await self._launch_tensorboard(job_id, section_printer)
            elif choice == "yes":
                await self._launch_tensorboard(job_id, section_printer)
            else:  # "no"
                self._show_manual_tensorboard_instructions(job_id, section_printer)
        else:  # "never"
            self._show_manual_tensorboard_instructions(job_id, section_printer)

    async def _launch_tensorboard(self, job_id: str, section_printer=None):
        """Launch TensorBoard and show info.

        Args:
            job_id: Training job identifier
            section_printer: Section printer for indented output
        """

        from arc.core.config import SettingsManager

        logdir = Path(f"tensorboard/run_{job_id}")

        try:
            settings = SettingsManager()
            port = settings.get_tensorboard_port()

            url, pid = self.tensorboard_manager.launch(job_id, logdir, port)

            if section_printer:
                section_printer.print("")
                section_printer.print("[green] Launching TensorBoard...[/green]")
                section_printer.print(f"  â€¢ URL: [bold]{url}[/bold]")
                section_printer.print(f"[dim]  â€¢ Process ID: {pid}[/dim]")
                section_printer.print(f"[dim]  â€¢ Logs: {logdir}[/dim]")
                section_printer.print("")
                section_printer.print(
                    f"[dim]  To stop: /ml tensorboard stop {job_id}[/dim]"
                )
            else:
                self.ui._printer.console.print()
                self.ui._printer.console.print(
                    "[green] Launching TensorBoard...[/green]"
                )
                self.ui._printer.console.print(f"  â€¢ URL: [bold]{url}[/bold]")
                self.ui._printer.console.print(f"  â€¢ Process ID: {pid}")
                self.ui._printer.console.print(f"  â€¢ Logs: {logdir}")
                self.ui._printer.console.print()
                self.ui._printer.console.print(
                    f"  To stop: /ml tensorboard stop {job_id}"
                )
        except (OSError, RuntimeError) as e:
            # Known TensorBoard launch failures
            if section_printer:
                section_printer.print(
                    f"[yellow]  Failed to launch TensorBoard: {e}[/yellow]"
                )
            else:
                self.ui._printer.console.print(
                    f"[yellow]  Failed to launch TensorBoard: {e}[/yellow]"
                )
            self._show_manual_tensorboard_instructions(job_id, section_printer)
        except Exception as e:
            # Log unexpected errors with full traceback
            import logging

            logging.exception("Unexpected error during TensorBoard launch")
            error_msg = f"{e.__class__.__name__}: {e}"
            if section_printer:
                section_printer.print(
                    f"[yellow]  Failed to launch TensorBoard: {error_msg}[/yellow]"
                )
            else:
                self.ui._printer.console.print(
                    f"[yellow]  Failed to launch TensorBoard: {error_msg}[/yellow]"
                )
            self._show_manual_tensorboard_instructions(job_id, section_printer)

    def _show_manual_tensorboard_instructions(self, job_id: str, section_printer=None):
        """Show manual TensorBoard instructions.

        Args:
            job_id: Training job identifier
            section_printer: Section printer for indented output
        """
        logdir = f"tensorboard/run_{job_id}"
        if section_printer:
            section_printer.print("")
            section_printer.print("[dim][cyan]9 Track training:[/cyan][/dim]")
            section_printer.print(f"[dim]  â€¢ Status: /ml jobs status {job_id}[/dim]")
            section_printer.print(
                f"[dim]  â€¢ TensorBoard: tensorboard --logdir {logdir}[/dim]"
            )
        else:
            self.ui._printer.console.print()
            self.ui._printer.console.print("[cyan]9 Track training:[/cyan]")
            self.ui._printer.console.print(f"  â€¢ Status: /ml jobs status {job_id}")
            self.ui._printer.console.print(
                f"  â€¢ TensorBoard: tensorboard --logdir {logdir}"
            )

    def _create_validator(self):
        """Create validator function for the workflow."""

        def validate(yaml_str: str) -> list[str]:
            try:
                trainer_dict = yaml.safe_load(yaml_str)
                validate_trainer_dict(trainer_dict)
                return []  # No errors
            except yaml.YAMLError as e:
                return [f"Invalid YAML: {e}"]
            except TrainerValidationError as e:
                return [f"Validation error: {e}"]
            except Exception as e:
                return [f"Unexpected error: {e}"]

        return validate

    def _create_editor(self, _user_instruction: str, model_record):
        """Create editor function for AI-assisted editing with conversation history."""

        async def edit(
            yaml_content: str,
            feedback: str,
            context: dict[str, Any],
            conversation_history: list[dict[str, str]] | None = None,
        ) -> tuple[str | None, list[dict[str, str]] | None]:
            # Extract knowledge IDs from feedback
            from arc.core.agents.shared.knowledge_selector import (
                extract_knowledge_ids_from_text,
            )

            recommended_knowledge_ids = extract_knowledge_ids_from_text(
                instruction=feedback,
                ml_plan_architecture=None,
            )

            agent = MLTrainAgent(
                self.services,
                self.api_key,
                self.base_url,
                self.model,
            )

            try:
                (
                    _trainer_spec,
                    edited_yaml,
                    updated_history,
                ) = await agent.generate_trainer(
                    name=context["trainer_name"],
                    instruction=feedback,
                    model_id=model_record.id,
                    model_spec_yaml=model_record.spec,
                    existing_yaml=yaml_content,
                    recommended_knowledge_ids=recommended_knowledge_ids,
                    conversation_history=conversation_history,
                )
                return edited_yaml, updated_history
            except Exception as e:
                if self.ui:
                    self.ui.show_system_error(f"L Edit failed: {e}")
                return None, None

        return edit
